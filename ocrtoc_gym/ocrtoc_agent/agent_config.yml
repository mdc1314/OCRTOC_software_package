# This is the default config file which is loaded by run.py. It contains all the parameters that can be specified for
# the evaluation of an Agent. The parameters are explained in more detail in ocrtoc_gym/ocrtoc_env/src/evaluate_agent.py

# task env:
# "0_0"
# "1_1_1","1_1_2","1_1_3",
# "1_2_1","1_2_2",
# "1_3_1",
# "1_4_1","1_4_2",
# "1_5_1","1_5_2","1_5_3",
# "2_1_1","2_1_2",
# "2_2_1","2_2_2","2_2_3","2_2_4",
# "3_1_1","3_1_2", 
# "3_2_1","3_2_2",
# "3_3_1","3_3_2",
# "4_1_1","4_1_2",
# "4_2_1","4_2_2","4_2_3","4_2_4",
# "4_3_1","4_3_2","4_3_3","4_3_4",
# "5_2_1","5_2_2",
# "6_1_1","6_1_2",
# "6_2_1","6_2_2","6_2_3",
# "6_3_1","6_3_2","6_3_3"
# you can use the shortcuts e.g. "1-1" to evaluate "1_1_1", "1_1_2" ,and "1_1_3"

####################### Execution Parameters ####################################
render: True
n_episodes: 2 # How many episodes one environment will run
n_cores: 1 # How many cores will be used, -1 takes all cores and 1 will not parallelize the program
tasks_type: "pose" # specify task type, "pose" and "language"

####################### Pose Conditioned Tasks ####################################
env: ["1_1_1"] # What environments are evaluated can specify multiple environments
debug: True # If render is true and debug is true, there will be transparent target objects on GUI. In Evaluation process , current and target bounding boxes will be drawn
# Evaluation paramter
IoU_threshold: 0.6 # Threshold of Intersection over Union for current and target bounding boxes, the IoU above this value is seen as success

####################### Language Conditioned Tasks ####################################
object_category: 3    ## How many categories of object in the env [1,6] 
object_max_num: 1  ## Max number of each object  [1,4] 
overlap: True      ## If objects can be overlapped to each other
object_class: "grocery" ## object class, "tool" , "fruit", or "grocery"

####################### Model parameters ####################################
# Transformation (euler is intrinsic order xyz)
world_to_panda: [-0.42,0.0 ,0.0, 0.0 ,0.0 ,0.0]   # panda link0 w.r.t to world
in_hand_camrea_to_panda_hand: [0.0525, 0.0, 0.0, 0.0 ,-0.261799, -1.57] # realsense w.r.t panda hand
fix_camera_to_panda: [1.3, 0.0, 1.3,-3.142, -0.698132 ,1.571] #realsense2 w.r.t panda link0 
# Realsense:
camera_to_camera_link: [0.0149, 0.0175, 0.0125, 0, 0 ,0] # realsense link w.r.t to realsense 
camera_link_to_rgb_frame: [0.015, 0.0, 0.0 ,0 ,3.14, 0] # rgb optical frame to realsense link
camera_link_to_depth_frame: [0.0, 0.0, 0.0 ,0 , 3.14, 0] # depth optical frame to realsense link
camera_width: 640
camera_height: 480

####################### Agent Parameters ####################################
# You can specify your own parameters here, they will be passed to the init of your Agent and won't be overwritten in final evaluation